# Open Source Models using Hugging Face

In this project, I did select open source models from Hugging Face Hub to perform NLP, audio, image and multimodal tasks using the Hugging Face transformers library. Easily packaged the code into a user-friendly app that I run on the cloud using Gradio and Hugging Face Spaces.

# Project details

- Provider: Coursera- DeepLearning.AI
- Language: English
- Instructors: Younes Belkada, Marc Sun, Maria Khalusova

# Tasks

1. Use the transformers library to turn a small language model into a chatbot capable of multi-turn conversations to answer follow-up questions.

2. Translate between languages, summarize documents, and measure the similarity between two pieces of text, which can be used for search and retrieval.

3. Convert audio to text with Automatic Speech Recognition (ASR), and convert text to audio using Text to Speech (TTS).

4. Perform zero-shot audio classification, to classify audio without fine-tuning the model.

5. Generate an audio narration describing an image by combining object detection and text-to-speech models.  

6. Identify objects or regions in an image by prompting a zero-shot image segmentation model with points to identify the object that you want to select.

7. Implement visual question answering, image search, image captioning and other multimodal tasks.

8. Share your AI app using Gradio and Hugging Face Spaces to run your applications in a user-friendly interface on the cloud or as an API.

# Roadmap - exercises

1. Chatbot basics using Facebook BlenderBox model from Hugging face
2. Translation and summarization using Facebook nnlb and bart-large-cnn models
3. Sentence similarity using all-MiniLM-L6-v2 model

# Outcome

[The link to the app]()

 
